[
  {
    "path": "SDMs/2022-04-12-p1_ext_occ/",
    "title": "(Part 1) Extending the occupancy model with nimbleEcology: random effects",
    "description": "Putting group random effects into your models can be easy.",
    "author": [
      {
        "name": "Ben R. Goldstein",
        "url": {}
      }
    ],
    "date": "2022-04-12",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIn this post…\r\nRandom effects in\r\noccupancy modeling\r\nNext time…\r\n\r\nIn this post…\r\nI extend the occupancy model by modifying the standard occupancy\r\nNIMBLE model code to include a group random effect.\r\nThis post is short, and is meant more to provide example code than to\r\noffer in-depth explanations of these concepts. It’s the first in a\r\nthree-part series on some basic ways to do more with the occupancy\r\nmodel.\r\nI assume that you’ve read my earlier post, Intro\r\nto nimbleEcology: Marginalization and the occupancy model. I’ll be\r\nusing code and data from this previous post.\r\n\r\n\r\n\r\nRandom effects in\r\noccupancy modeling\r\nRandom effects are an important concept I won’t cover fully here. In\r\nthis example we’ll be thinking of random effects as a way to\r\nappropriately count for groupings or non-independence between\r\nobservations in an occupancy model.\r\nToday’s hypothetical observation study starts out the same as in the\r\nlast post. We’ve sampled a number of sites, and on each we recorded\r\nwhether or not we detected white-throated swifts. However, there’s a\r\ntwist: the sites we sampled were each in one of three regions that have\r\ndifferent properties. In this case, we’ll say each region was associated\r\nwith a different detection probability. We need to properly account for\r\nthose differences using random effects.\r\nIf we don’t account for this important driver of variation, a number\r\nof bad things could happen. For one, this would be an issue of\r\npseudoreplication, meaning we have unaccounted-for non-independence\r\nbetween observations that will reduce the observed variance and make our\r\nestimated error overconfident. (Pseudoreplication in ecological field\r\nexperiments was discussed in this\r\npaper by Hurlburt in 1984.) On top of that basic issue, our\r\noccupancy model makes an assumption that there isn’t extra variation in\r\ndetection heterogeneity in order to partition variation between\r\noccupancy and detection processes. If the interdependence is in the\r\ndetection process, that missing variation will show up as detection\r\nestimates that are biased upward and occupancy estimates that are biased\r\ndownward.\r\nSo, we want to implement random effects of group on detection in our\r\nmodel. Let’s start by writing out the occupancy model equations, this\r\ntime with the inclusion of the random effect.\r\n\\[y_{ij} \\sim \\text{Bernoulli}(z_i \\times\r\np_{ij})\\] \\[z_i \\sim\r\n\\text{Bernoulli}(\\psi_i)\\] \\[\\text{logit}(\\psi_{i}) = x_{i}^T\\beta\\]\r\n\\[\\text{logit}(p_{ij}) = w_{ij}^T\\gamma +\r\n\\alpha_{R(i)}\\] \\[\\alpha_r \\sim\r\n\\mathcal{N}(0, sigma_\\alpha) \\text{ for } r \\text{ in }\r\n1...R\\]\r\nThe only changes from our previous equations are the inclusion of the\r\n\\(\\alpha_{R(i)}\\) and fifth equation\r\ndefining that element. The addition of \\(\\alpha_{R(i)}\\) to the linear combination\r\nin Equation 4 means that there’s some quantity that we’re adding to our\r\n(logit-scale) detection probability. The indexing \\(R(i)\\) means that there are R elements (in\r\nour example, \\(R=3\\) regions), and\r\nwe’ll know which element we need as a function of site \\(i\\). For example, all observations at the\r\n\\(i=5\\)th site are in Region 1 \\((R(5)=1)\\).\r\nThe new fifth equation defines a distribution for these random\r\neffects. We say they’re normally distributed with mean 0 and a standard\r\ndeviation parameter \\(sigma_\\alpha\\)\r\nthat we’ll estimate. It’s normal to use Gaussian random effects. It’s\r\nimportant that the mean is 0 rather than a parameter as otherwise they’d\r\nbe redundant with the intercept parameter we’re already estimating.\r\nHere is some NIMBLE code implementing the model.\r\n\r\n\r\nlibrary(nimbleEcology)\r\n\r\n# Because this code is mostly copied from the previous post, I'll only put\r\n# comments on new features.\r\n\r\noccuCode_w_random_effects <- nimbleCode({\r\n  # Loop over sites\r\n  for (site in 1:nSites) {\r\n    obs[site, 1:nReps] ~ dOcc_v(\r\n      probOcc = psi[site], \r\n      probDetect = p[site, 1:nReps],\r\n      len = nReps\r\n    )\r\n    logit(psi[site]) <- inprod(occuCovars[site, 1:nBeta], beta[1:nBeta])\r\n    \r\n    # Loop over reps\r\n    for (rep in 1:nReps) {\r\n      logit(p[site, rep]) <- inprod(detectionCovars[site, rep, 1:nGamma],\r\n                                    gamma[1:nGamma]) +\r\n                             ranef[region[site]]\r\n      # Above, we added an additive random effect to each obs's detection\r\n      # probability. \"ranef\" is a vector of length nRegion, each value of which\r\n      # is the shared random effect. We used nested indexing by providing a\r\n      # vector \"region\" with values 1, 2,...nRegion. region[i] tells us which\r\n      # region the ith site belongs to. This effect is additive on logit(p).\r\n      \r\n    } # END reps loop\r\n  } # END site loop\r\n\r\n  # Priors on each covariate on occupancy:\r\n  for (i in 1:nBeta) {\r\n    beta[i] ~ dnorm(0, sd = 2.5)\r\n  }\r\n  # Priors on each covariate on detection:\r\n  for (i in 1:nGamma) {\r\n    gamma[i] ~ dnorm(0, sd = 2.5)\r\n  }\r\n  \r\n  # We need to add the distribution for the random effects.\r\n  for (i in 1:nRegion) {\r\n    ranef[i] ~ dnorm(0, sigma_region)\r\n  }\r\n  # Finally, we need a prior on our new parameter, sigma_region\r\n  \r\n})\r\n\r\n\r\n\r\nHere is some NIMBLE code describing the same model.\r\nTo recap, the steps we took in our code were:\r\nAdd a dynamically indexed vector to our logit-scale detection\r\nprobability\r\nLoop over this vector and define each element as random normal with\r\na common standard deviation\r\nThese are the exact same changes we made to our model equations.\r\nYou can use multiple random effects, added onto each other, and you\r\ncan use random effects in the occupancy submodel (additive on \\(\\text{logit}(\\psi)\\)). It’s also possible\r\nto use random effects in a standard NIMBLE occupancy model without the\r\nmarginalized setup offered by nimbleEcology.\r\nBuilding the model will look pretty similar. We just need to provide\r\nthe value nRegion = 3 in constants, and a vector,\r\nregion, where region[i] gives the numerical\r\nindex of the \\(i\\)th observation’s\r\nassociated random effect (in this case either 1, 2, or 3.)\r\n\r\n\r\ndim(obs) # The data have 3 observations at each of 200 sites\r\n\r\n\r\n[1] 200   3\r\n\r\nlength(region) # Each site has a region associated with it\r\n\r\n\r\n[1] 200\r\n\r\ntable(region) # 75 sites are in region 1, 75 are in region 2, and 50 are in 3\r\n\r\n\r\nregion\r\n 1  2  3 \r\n75 75 50 \r\n\r\nWe also want to provide initial values for our new nodes–the\r\nparameter sigma_region and the random effects vector ranef. So with all\r\nthat in mind, let’s jump in to building the model. I’ll flag the changes\r\nfrom last time with comments.\r\n\r\n\r\noccu_model_w_random_effects <- nimbleModel(\r\n  code = occuCode_w_random_effects,\r\n  constants = list(\r\n    nBeta = 3,\r\n    nGamma = 4,\r\n    nSites = nrow(obs),\r\n    nReps = ncol(obs),\r\n    nRegion = 3, # New!\r\n    region = region # New!\r\n  ),\r\n  data = list(\r\n    obs = obs,\r\n    detectionCovars = \r\n      obsLevelData[,, c(\"intercept\", \"elevation\", \"forestCover\", \"windLevel\")],\r\n    occuCovars = siteLevelData[, c(\"intercept\", \"elevation\", \"forestCover\")]\r\n  ),\r\n  inits = list(\r\n    beta = rnorm(3),\r\n    gamma = rnorm(4),\r\n    ranef = rnorm(3), # New!\r\n    sigma_region = 1.2 # New!\r\n  )\r\n)\r\n\r\noccu_model_w_random_effects$calculate()\r\n\r\n\r\n[1] -331.1213\r\n\r\nNow we can proceed with compiling and running MCMC as usual. We’ll\r\nget a posterior distribution for the random effect standard deviation,\r\nsigma_region.\r\nAll code used in this post, including hidden code used to generate\r\nthe data, can\r\nbe found here.\r\nNext time…\r\nThis post will be followed by two similarly short posts providing\r\nmore example code for fun things you can do with occupancy models using\r\nnimbleEcology. In those I’ll discuss maximum likelihood estimation with\r\nNIMBLE and give an example of a multispecies occupancy model.\r\nIf you have any requests for content, please reach out!\r\n\r\n\r\n\r\n",
    "preview": "SDMs/2022-04-12-p1_ext_occ/images/ranefvis.png",
    "last_modified": "2022-04-12T14:40:09-07:00",
    "input_file": {}
  },
  {
    "path": "SDMs/2022-01-31-intro-to-nimbleecology-site-occupancy-models/",
    "title": "Intro to nimbleEcology: Marginalization and the occupancy model",
    "description": "An introductory guide to estimating site-occupancy models in a Bayesian or maximum likelihood framework.",
    "author": [
      {
        "name": "Ben R. Goldstein",
        "url": {}
      }
    ],
    "date": "2022-02-22",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIn this post…\r\nWhat is nimbleEcology?\r\nWhat is marginalization?\r\nWhy should I use nimbleEcology marginalized distributions?\r\n\r\nOverview of the site-occupancy model\r\nStructure\r\n\r\nA marginalized occupancy distribution, dOcc\r\nImplementing the occupancy model with nimbleEcology\r\nNext time…\r\nCitations and additional reading\r\n\r\nIn this post…\r\nI introduce the concept of “marginalization” in a hierarchical model through the context of the occupancy model.\r\nI assume a basic familiarity with the occupancy model, which I define in the section “Overview of the site-occupancy model” below, and a basic familiarity with / exposure to Bayesian model estimation (MCMC). Neither of these is strictly necessary to get the main points in this blog post. See “Citations and additional reading” for related materials.\r\nI focus on an R package I co-authored, nimbleEcology, in which we’ve implemented some marginalized distributions for common ecological models.\r\nWhat is nimbleEcology?\r\nnimbleEcology is an R package that makes it easier to implement some common ecological models in the general statistical software NIMBLE. Specifically, nimbleEcology provides marginalized distributions that turn hierarchical structures with latent states, such as the occupancy or N-mixture model, into one line distributions similar to familiar distributions like dpois() or dbinom().\r\nIn this blog post, I show how the entire occupancy hierarchical probability distribution for the occupancy model can be written with y ~ dOcc_v(...) and provide a working example.\r\nWhat is marginalization?\r\nModel fitting, whether working with Bayesian or maximum likelihood tools, always involves calculating the likelihood of a model. In MLE, we often calculate the likelihood of a set of parameters given our data and numerically optimize those parameters to estimate the maximum of the likelihood function (hence “maximum likelihood estimation”). This is how popular MLE packages for ecological models like unmarked work under the hood. In Bayesian statistics, we don’t directly optimize the likelihood, but we do calculate it for a set of parameters when deciding whether to accept a newly sampled value during MCMC sampling.\r\nWhen we have latent states and random effects in our model, calculating the likelihood becomes more complicated. We don’t include values for latent states in the total model likelihood, because by definition random effects and latent states are not technically parameters we’re estimating–that’s what differentiates them from fixed effects. Instead we want to know the likelihood of our parameters, given the data and a random effect/latent state structure with specific random effects/latent states that could have any value in their domain. To optimize the likelihood without optimizing specific random effect values, you have to calculate and integrate over all possible values of each random effect.\r\n(A brief note here on latent states. I’m honestly not sure what the definition of “latent state” is. In practice in ecology, a latent state is a piece of model structure that represents an unobserved part of the system, usually as part of a hierarchical structure. I believe you can usually think of latent states as a type of random effect. Latent states come up in species distribution modeling as underlying occupancy conditions or abundance conditions. They can also come up in multi-state models of animal movement or survival.)\r\nThe rapid expansion of Bayesian methods in ecology has both obscured and been spurred by the fact that writing explicit likelihoods that integrate over random effects / marginalize over latent states is often impossible. In Bayesian statistics, you can sample the random effect without having to marginalize over it due to magic math. This is nice in cases like continuous random effects where integrating would require complicated approximators, and also in cases like hierarchical modeling where it’s intuitive to see the model structure written out.\r\nBut if we want to use maximum likelihood, and for some Bayesian applications, it is sometimes possible to marginalize over or integrate over a latent state or random effect by hand. This means writing a likelihood function that considers all possible latent states and computes the likelihood as a weighted sum across those.\r\nThis idea still gives me a lot of trouble, so if you’re stuck on it, that’s okay–I’ll try to contextualize the effects and advantages of marginalization in a way that doesn’t rely on a nuanced statistical understanding. In a later section, we’ll look at the specific case of marginalizing the occupancy distribution as a specific example.\r\nWhy should I use nimbleEcology marginalized distributions?\r\nSome advantages:\r\nSimpler code. We went ahead and implemented the occupancy distribution so you don’t have to. This saves lines of code and hopefully reduces some of the headache that inevitably comes from debugging a new model.\r\nIt’s easily modifiable. Implementing models in nimbleEcology, compared to something like unmarked, makes it easier to modify and customize your model when you’re ready to get fancy.\r\nIt’s fairly efficient. nimbleEcology uses marginalized distributions, saving memory and sometimes (but not always) increasing computational efficiency.\r\nSwap between MLE or Bayesian methodology. This maybe isn’t a need so much as an interesting feature, but with NIMBLE you have access to both maximum likelihood and Bayesian (MCMC) estimation with very few changes to the model code.\r\nSome important disadvantages of using marginalized distributions:\r\nNo access to posterior distributions of latent states. It’s fairly common now for ecologists to create derived products by summarizing latent states, such as obtaining a posterior on the total number of occupied sites. Because we aren’t sampling the latent state if we marginalize, we can’t do this.\r\nIt’s sometimes less efficient for MCMC. The paper that generated much of the code that eventually became nimbleEcology is Ponisio et al. 2020, “One size does not fit all: Customizing MCMC methods for hierarchical models using NIMBLE.” The title does a great job of summarizing their findings: Dr. Ponisio and colleagues found that marginalizing over latent states sometimes, but not always, improved MCMC efficiency.\r\nOverview of the site-occupancy model\r\nMuch has been written about the occupancy model, including entire textbooks and other very nice blog posts. I link to some of those at the bottom of the article. But here’s a very brief overview of this model’s structure.\r\nIf you feel comfortable implementing occupancy models, you can skip ahead to the next section: “Implementing the occupancy model with nimbleEcology”\r\nIn species distribution modeling, we often want to ask whether a species’ presence on the landscape is correlated with a spatio-temporal variable. For example, we might be interested in whether a species prefers dense or sparse tree cover, whether a species’ range is growing or declining over time, or whether a management strategy is actually working to attract a species.\r\nTo answer the question, we go out and collect data. We visit a gradient of sites across the variable of interest (such as some densely forested sites and some sparsely forested sites) and write down when we do and don’t detect the animal. We then often want to use statistical modeling to differentiate between the occupancy and detection processes–i.e., whether we detected the species less because it was truly there less, or just because it was harder to detect.\r\nSite-occupancy models are a type of statistical structure that allow us to ask these questions when our detection process is imperfect, so we can’t be confident that a nondetection means the species wasn’t there.\r\nStructure\r\nLet’s start by putting down some statistical equations for the simplest hierarchical site-occupancy model.\r\n\\[y_{ij} \\sim \\text{Bernoulli}(z_i \\times p_{ij})\\] \\[z_i \\sim \\text{Bernoulli}(\\psi_i)\\] \\[\\text{logit}(\\psi_{i}) = x_{i}^T\\beta\\] \\[\\text{logit}(p_{ij}) = w_{ij}^T\\gamma\\]\r\nwhere \\(i\\) and \\(j\\) index site and replicate visit, respectively; \\(y_{ij}\\) is a single detection or nondetection (1 or 0) at site \\(i\\), replicate \\(j\\); \\(z_i\\) is a latent state representing occupancy; \\(\\psi_i\\) is the probability that site \\(i\\) is occupied; \\(p_{ij}\\) is an observation-specific conditional detection probability; \\(x_i\\) and \\(w_{ij}\\) are vectors of covariates of interest; and \\(\\beta\\) and \\(\\gamma\\) are vectors of coefficients representing the effect of covariates on occupancy and detection, respectively.\r\nPhew. Let’s break that down.\r\nIn the first equation, we describe the probability distribution for our detection-nondetection observations, \\(y_{ij}\\). We say that each data point is Bernoulli-distributed: we have a probability of \\(z_i \\times p_{ij}\\) of seeing the animal. Since we either see it or we don’t, the probability of not seeing the animal is \\(1 - z_i \\times p_{ij}\\).\r\nIn the occupancy model, we assume that each “site” is in fact occupied or unoccupied, but that we can’t observe this condition perfectly. (I put “site” in quotation marks because the “site” need not be strictly spatial–for example, we could treat the occupancy status of a single location in different years as independent. Because the assumption that occupancy status doesn’t change is called “closure,” we can also call this unit a “unit of closure.”) In our second equation, we represent this with the latent state \\(z_i\\), which has a value of 1 if site \\(i\\) is occupied and 0 if it is not. If the site is unoccupied, we have no chance of seeing the animal. In that case, \\(z_i = 0\\) and the probability of \\(y_ij = 1\\) is also 0. Think of \\(z_i\\) as a switch that turns the probability of seeing the animal on or off. The “conditional probability of detection,” i.e. the probability that we see the animal when it’s present on a given observation, is \\(p_ij\\). It’s conditional because it only affects the data likelihood when \\(z_i =1\\). In the second equation, we define the distribution for the latent state \\(z_i\\), which has a probability of \\(\\psi_i\\).\r\nThe third equation links our probability of occupancy, \\(\\psi_i\\), to covariates. We say that, on the logit scale (which is a popular but largely arbitrary transformation from \\((-\\infty, \\infty)\\) to \\((0, 1)\\)), \\(\\psi_i\\) is a linear combination of some observed data describing our site, \\(x_{i}\\), with coefficients \\(\\beta\\). We want to estimate \\(\\beta\\) to get confidence or credible intervals on those effects.\r\nThe fourth equation replicates this logit-link structure for our detection probability, \\(p\\), and some covariates \\(w\\) with coefficients \\(\\gamma\\). The detection probability gives the Bernoulli probability that you observe the animal in question on a visit to an occupied site, i.e. the probability that \\(y_{ij}=1\\) given that \\(z_i = 1\\).\r\nA marginalized occupancy distribution, dOcc\r\nIgnoring covariates, the non-marginalized occupancy distribution is written (in NIMBLE code) as\r\n\r\n\r\nnimbleCode({\r\n  for (i in 1:nsite) {\r\n    z[i] ~ dbern(psi)\r\n    for (j in 1:nrep) {\r\n      y[i, j] ~ dbern(z[i] * p)\r\n    }\r\n  }\r\n})\r\n\r\n\r\n\r\nIn this setup we’ve coded a latent state, z, and defined it as following a Bernoulli distribution. Then we’ve said that our data, y, follow another Bernoulli distribution incorporating the state z.\r\nI want to marginalize over \\(z_i\\) and completely eliminate it from my model. To do this, I consider that the Bernoulli distribution means \\(z\\) can actually only have two states: either \\(z_i=1\\) with probability \\(\\psi\\) or \\(z_i=0\\) with probability \\(1-\\psi\\) .\r\nThen, I notice that, if we know what \\(z_i\\) is, the probability of \\(y_{ij}\\) is easy\r\nBut, recall that \\(z_i\\) influences the likelihood of every \\(y_{ij}\\). This means that our likelihood function needs to take into account all the observations in \\(y_{ij}\\) simultaneously, because the probability is interdependent between them. For example, the likelihood of \\(\\psi_i=0\\) will be exactly 0 for all observations \\(y_{ij}\\) if any of them are nonzero, since an unoccupied site can’t produce nonzero observations under this model.\r\nThus, the marginalized likelihood of parameters given the observations at site i is\r\n\\[L(\\psi,p|y_{i.}) = \\psi p^k (1-p)^{n-k} + (1-\\psi)I(k = 0)\\]\r\nwhere \\(n\\) is the number of observations at site \\(i\\), \\(k\\) is the number of nonzero observations at site \\(i\\), and \\(I(k=0)\\) is an indicator that takes 1 if \\(k\\) is 0 and 0 otherwise.\r\nIn plain English: the likelihood of our parameters given our data is the probability that the site is occupied times the probability of the data given that the site is occupied, plus the probability that the site isn’t occupied times the probability of the data given that it isn’t (which is 1 if all observations are 0, and 0 otherwise). We sum the two probabilities because either one or the other is true, but not both.\r\nWe’ve now marginalized over \\(z\\) by literally writing the values it could take and the associated probabilities of the data, then summing across them. Marginalizing isn’t always this straightforward, because latent states can take many (or infinitely many) values. We’ll explore harder contexts in future posts.\r\nYou don’t actually need to know any of that math for what follows, because we’ve coded it up for you.\r\nImplementing the occupancy model with nimbleEcology\r\n\r\n\r\n\r\nFigure 1: Swift (c) J Tanner 2022. https://macaulaylibrary.org/asset/409111121\r\n\r\n\r\n\r\n\r\n\r\nIn this section, I showcase the use of nimbleEcology for implementing an occupancy model with simulated data.\r\nLet’s say we have some data we collected in a study on how the occupancy of a bird, the white-throated swift. I have my detection/nondetection data in a matrix called “obs”. We surveyed 200 sites three times each, and recorded whether or not we observed swifts during those surveys.\r\nHere are the first six rows in the data:\r\n\r\n\r\nhead(obs)\r\n\r\n\r\n     [,1] [,2] [,3]\r\n[1,]    0    0    0\r\n[2,]    0    0    0\r\n[3,]    1    1    0\r\n[4,]    0    0    1\r\n[5,]    1    0    1\r\n[6,]    0    0    0\r\n\r\nWe detected the swift at three of the first six sites. Here are a few more summary statistics:\r\n\r\n\r\n# Total number of sites with detections (\"naive occupancy\")\r\nsum(rowSums(obs) > 0)\r\n\r\n\r\n[1] 69\r\n\r\n# Average number of observations per occupied site\r\nmean(obs[rowSums(obs) > 0, ])\r\n\r\n\r\n[1] 0.4879227\r\n\r\nWe want to know how the elevation and amount of forest cover impact the occupancy of our swifts in the study area. We measured elevation and forest cover at each of our sites. Here’s the first six sites’ data:\r\n\r\n\r\nhead(siteLevelData)\r\n\r\n\r\n   elevation forestCover\r\n1 -0.9559221  0.37841493\r\n2 -0.9790799 -0.01406795\r\n3  0.4368064  0.17601854\r\n4 -0.7193709 -0.92947860\r\n5 -0.2721558 -0.43107788\r\n6  0.0428613  0.49594396\r\n\r\n(In the previous section, each row of these data are an \\(x_i\\).)\r\nWe’re using an occupancy model because we think our data contains false negatives–i.e., sometimes we didn’t see a swift at an occupied site. We think that sometimes, high wind conditions could reduce our ability to see swifts. And we also don’t want to rule out the possibility that detection probabilities vary with elevation or tree cover. Disambiguating the effects of a single variable on both detection and probability is one of the main benefits of th occupancy model.\r\nHere’s data from the first six sites for our three detection variables.\r\n\r\n\r\nhead(obsLevelData[,,\"elevation\"])\r\n\r\n\r\n           [,1]       [,2]       [,3]\r\n[1,] -0.9559221 -0.9559221 -0.9559221\r\n[2,] -0.9790799 -0.9790799 -0.9790799\r\n[3,]  0.4368064  0.4368064  0.4368064\r\n[4,] -0.7193709 -0.7193709 -0.7193709\r\n[5,] -0.2721558 -0.2721558 -0.2721558\r\n[6,]  0.0428613  0.0428613  0.0428613\r\n\r\nhead(obsLevelData[,,\"forestCover\"])\r\n\r\n\r\n            [,1]        [,2]        [,3]\r\n[1,]  0.37841493  0.37841493  0.37841493\r\n[2,] -0.01406795 -0.01406795 -0.01406795\r\n[3,]  0.17601854  0.17601854  0.17601854\r\n[4,] -0.92947860 -0.92947860 -0.92947860\r\n[5,] -0.43107788 -0.43107788 -0.43107788\r\n[6,]  0.49594396  0.49594396  0.49594396\r\n\r\nhead(obsLevelData[,,\"windLevel\"])\r\n\r\n\r\n          [,1]       [,2]       [,3]\r\n[1,] 0.5818751  0.6126206 -0.7922553\r\n[2,] 0.2276861  0.7952973 -0.6619532\r\n[3,] 0.9545355 -0.6955473 -0.6014542\r\n[4,] 0.8137390  0.4535272  0.6110631\r\n[5,] 0.5897824 -0.3132945  0.1687786\r\n[6,] 0.3905541  0.3720862 -0.2839954\r\n\r\nFor the sake of simplicity, we’ll assume that our sites are random and representative of the study area, that we have good reason to believe we aren’t recording false positive observations, and that we don’t think our detection process is variable except due to the factors we’re considering (wind, forest cover, and elevation).\r\nLet’s get to modeling!\r\n\r\n\r\nlibrary(nimble)\r\nlibrary(nimbleEcology)\r\n\r\n\r\n\r\nFirst, to use NIMBLE, we’re going to define a nimbleCode object. This code object uses a pseudo-code language, blending .\r\nNIMBLE uses a declarative language, meaning order doesn’t matter. A consequence of this is that you can’t overwrite values. Instead of stepping through lines of code, think of nimbleCode as defining relationships between variables (nodes). For a more in-depth overview of the NIMBLE code language check out the NIMBLE User Manual, which I link at the end of the post.\r\nOk, enough stalling. Here’s the NIMBLE code for our model, with comments.\r\n\r\n\r\noccuCode <- nimbleCode({\r\n  # Loop over sites\r\n  for (site in 1:nSites) {\r\n    # Here's the nimbleEcology magic: the dOcc_* distribution.\r\n    # This line of code says that our observations follow a probability\r\n    #   distribution in the occupancy model, with a single occupancy probability\r\n    #   and a vector of detection probabilities corresponding to each \r\n    #   observation. Note that we pass a whole site's worth of data at once.\r\n    # Try running ?nimbleEcology::dOcc in your R session for more info.\r\n    obs[site, 1:nReps] ~ dOcc_v(\r\n      probOcc = psi[site], \r\n      probDetect = p[site, 1:nReps],\r\n      len = nReps\r\n    )\r\n    \r\n    # We define a logit-linear relationship between occupancy probability\r\n    #   psi and some covariate data we'll provide.\r\n    # inprod(x, y) is the same as x[1] * y[1] + x[2] * y[2] + ... + x[n] * y[n]\r\n    #### Note that: ###\r\n    # - We can put logit() on the left-hand side like a model equation\r\n    # - The data intercept is represented in model matrix notation inside \r\n    #   occuCovars (more on that in a second)\r\n    # - We need EXPLICIT INDEXING for our vectors (beta[1:nBeta], not just beta).\r\n    #   This is an important difference between nimbleCode and base R\r\n    logit(psi[site]) <- inprod(occuCovars[site, 1:nBeta], beta[1:nBeta])\r\n    \r\n    # Loop over reps\r\n    for (rep in 1:nReps) {\r\n      # Do this again for each detection probability. Only difference is that\r\n      # p is now two-dimensional and detectionCovars is three-dimensional.\r\n      logit(p[site, rep]) <- inprod(detectionCovars[site, rep, 1:nGamma],\r\n                                    gamma[1:nGamma])\r\n    } # END reps loop\r\n  } # END site loop\r\n  \r\n  # Priors. We need these in order to do MCMC sampling. I'm going to choose some\r\n  # arbitrary, mostly uninformative priors.\r\n  # Priors on each covariate on occupancy:\r\n  for (i in 1:nBeta) {\r\n    beta[i] ~ dnorm(0, sd = 2.5)\r\n  }\r\n  # Priors on each covariate on detection:\r\n  for (i in 1:nGamma) {\r\n    gamma[i] ~ dnorm(0, sd = 2.5)\r\n  }\r\n})\r\n\r\n\r\n\r\nSome of this code might look unfamiliar to folks who have done Bayesian occupancy modeling before. I’ve gone out of my way to make things generalizable, using inprod() over, for example, intercept + elev[i] * b1 + forest[i] * b2. My motivation for doing this is that it’s super generalizable, and I’ll be able to add or remove covariates without making any changes to my code.\r\nNote that because we’re using nimbleEcology, we’ve “marginalized over” the latent state \\(z\\) and it’s not in the model. This is a good thing for a couple reasons: it reduces the amount of RAM needed, which can be important for large datasets; it slightly speeds up mixing time in some cases; and it saves some lines of code. However, there are often cases where we want \\(z\\), such as if we want a posterior distribution on the number of occupied sites. In that case we shouldn’t use nimbleEcology (but NIMBLE will do fine).\r\nThe next step in the NIMBLE workflow is to define a NIMBLE model object. This turns our code, which describes a series of nodes and the relationships between them, into an actual object composed of that structure.\r\nAll the data wrangling I have to do is just to get my inputs in the same form as I’ve described them.\r\nBecause I’m using inprod() I need to make sure my data have intercept columns first.\r\n\r\n\r\nsiteLevelData$intercept <- 1\r\nobsLevelData[,, \"intercept\"] <- 1\r\n\r\n\r\n\r\n\r\n\r\noccu_model <- nimbleModel(\r\n  code = occuCode,\r\n  constants = list(\r\n    nBeta = 3,\r\n    nGamma = 4,\r\n    nSites = nrow(obs),\r\n    nReps = ncol(obs)\r\n  ),\r\n  data = list(\r\n    obs = obs,\r\n    # I like indexing these here so I make sure they're going\r\n    #   into the model in the right order\r\n    detectionCovars = \r\n      obsLevelData[,, c(\"intercept\", \"elevation\", \"forestCover\", \"windLevel\")],\r\n    occuCovars = siteLevelData[, c(\"intercept\", \"elevation\", \"forestCover\")]\r\n  ),\r\n  inits = list(\r\n    beta = rnorm(3),\r\n    gamma = rnorm(4)\r\n  )\r\n)\r\n\r\n\r\n\r\nThat’s it! We now have a nimbleModel object.\r\nOne of my favorite things about working in NIMBLE is that we can play with and query the nimbleModel.\r\n\r\n\r\n# Peek inside the model: what are the data values for the 22nd site?\r\noccu_model$obs[22,]\r\n\r\n\r\n[1] 0 0 0\r\n\r\n# What's the corresponding site-level data at this site?\r\noccu_model$occuCovars[22,] # Intercept, elevation, tree cover\r\n\r\n\r\n[1]  1.0000000  0.2463764 -0.1503483\r\n\r\n# What's the log-likelihood of the model given initial values?\r\n# (If this is non-NA, that means our model is initialized properly)\r\noccu_model$calculate()\r\n\r\n\r\n[1] -303.6887\r\n\r\nIf we wanted to, we could modify data or initial values at this stage, but not constants, which are “baked in” to the model when its built.\r\nI’ll go quickly over this next part, since using MCMC with NIMBLE is better explained on the NIMBLE examples page (see: “Creating a default MCMC”). Briefly, we’re going to build an MCMC object and then compile the whole thing so we’re ready to do some MCMC sampling.\r\n\r\n\r\nmcmc <- buildMCMC(occu_model)\r\n\r\n\r\n===== Monitors =====\r\nthin = 1: beta, gamma\r\n===== Samplers =====\r\nRW sampler (7)\r\n  - beta[]  (3 elements)\r\n  - gamma[]  (4 elements)\r\n\r\n# Compile to C++. This takes a second, but it's worth it!\r\ncomplist <- compileNimble(occu_model, mcmc)\r\n\r\n# We can still query / modify the compiled model\r\ncomplist$occu_model$obs[22,]\r\n\r\n\r\n[1] 0 0 0\r\n\r\nNow let’s do some MCMC sampling. 10,000 MCMC samples on 2 chains is a bit overkill for this model, but it’s quick–this takes about 20 seconds to run on my machine.\r\n\r\n\r\nsamples <- runMCMC(complist$mcmc, \r\n                   niter = 10000,\r\n                   nburnin = 1000,\r\n                   nchains = 2,\r\n                   thin = 1,\r\n                   samplesAsCodaMCMC = TRUE)\r\n\r\n\r\n|-------------|-------------|-------------|-------------|\r\n|-------------------------------------------------------|\r\n|-------------|-------------|-------------|-------------|\r\n|-------------------------------------------------------|\r\n\r\nWe can plot some of our chains to see how they mixed, for example the logit-scale effect of elevation on occupancy, which is beta[2] (because beta[1] is the intercept).\r\n\r\n\r\nplot(samples[, \"beta[2]\"])\r\n\r\n\r\n\r\n\r\nI like the package MCMCvis for MCMC summaries.\r\n\r\n\r\n\r\n\r\n\r\nsummary <- MCMCvis::MCMCsummary(samples)\r\n\r\nsummary$param <- c(\"Intercept (occu)\", \"Elev (occu)\", \"Forest (occu)\",\r\n                   \"Intercept (det)\", \"Elev (det)\", \"Forest (det)\", \"Wind (det)\")\r\n\r\nsummary[, c(\"param\", \"mean\", \"2.5%\", \"97.5%\")]\r\n\r\n\r\n                    param   mean  2.5%  97.5%\r\nbeta[1]  Intercept (occu)  0.276 -0.40  1.428\r\nbeta[2]       Elev (occu)  0.878 -0.41  2.239\r\nbeta[3]     Forest (occu) -1.828 -3.48 -0.620\r\ngamma[1]  Intercept (det) -0.816 -1.31 -0.359\r\ngamma[2]       Elev (det)  0.506 -0.18  1.265\r\ngamma[3]     Forest (det)  0.037 -0.71  0.691\r\ngamma[4]       Wind (det) -0.503 -0.94 -0.078\r\n\r\nWe found a negative effect of forest cover on occupancy, and a negative effect of wind speed on detection. Nice.\r\nNext time…\r\nStay tuned for two follow up posts. In the first, I’ll discuss easy ways to extend the occupancy model in NIMBLE to showcase the flexibility of this tool. Then, I’ll showcase an N-mixture model, and we’ll explore a case where marginalizing over a latent state can dramatically improve computation time.\r\nThanks for reading! Hit the “contact me” button at the top of the page if you have any questions or feedback.\r\nCitations and additional reading\r\nAll the code in this exercise is available in the Github repository for this blog, specifically here. Please feel free to download and play around with this .Rmd file, and to copy and use this code freely.\r\nIf you want to see the code underlying the occupancy distribution used, it’s on this GitHub page. The nimbleEcology vignette is here.\r\nFor a really helpful blog post on implementing the occupancy model in NIMBLE without marginalization, check out Mason Fidino’s writeup here. Dr. Fidino’s blog was a big inspiration in getting this one off the ground.\r\nRelevant papers and books:\r\nOriginal MacKenzie et al. 2002 paper on site-occupancy model\r\nPonisio et al. 2020 paper marginalizing distributions in NIMBLE\r\nOccupancy Estimation and Modeling textbook by MacKenzie et al.\r\nAs always, check out the NIMBLE User Manual and the NIMBLE examples page for more NIMBLE stuff.\r\n\r\n\r\n\r\n",
    "preview": "SDMs/2022-01-31-intro-to-nimbleecology-site-occupancy-models/images/swift.png",
    "last_modified": "2022-04-12T13:40:23-07:00",
    "input_file": {}
  }
]
